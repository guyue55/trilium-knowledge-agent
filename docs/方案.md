æ–¹æ¡ˆ.md
# é›†æˆæœ¬åœ°çŸ¥è¯†åº“ Trilium Notes çš„æœ€ä½³æ–¹æ¡ˆ

å¯¹äºé›†æˆ Trilium Notes æœ¬åœ°çŸ¥è¯†åº“æ¥æä¾›æ›´ç²¾å‡†å›ç­”çš„æ™ºèƒ½ä½“ï¼Œæˆ‘æ¨èä½¿ç”¨ä»¥ä¸‹æŠ€æœ¯æ ˆï¼š

## ğŸ† æ ¸å¿ƒæ¡†æ¶é€‰æ‹©ï¼šFastAPI + LangChain

### ä¸ºä»€ä¹ˆè¿™ä¸ªç»„åˆæœ€åˆé€‚ï¼Ÿ
```python
# å®Œç¾å¥‘åˆç‚¹ï¼š
- âš¡ FastAPIï¼šè¶…é«˜æ€§èƒ½å¼‚æ­¥æ¡†æ¶ï¼Œé€‚åˆå®æ—¶æ™ºèƒ½ä½“å“åº”
- ğŸ¤– LangChainï¼šä¸“ä¸ºçŸ¥è¯†åº“é›†æˆè®¾è®¡çš„AIæ¡†æ¶ï¼Œå†…ç½®Triliumæ”¯æŒ
- ğŸ” å¼ºå¤§çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)èƒ½åŠ›ï¼šç²¾å‡†æå–çŸ¥è¯†åº“å†…å®¹
- ğŸ§  æœ¬åœ°æ¨¡å‹æ”¯æŒï¼šå¯å®Œå…¨ç¦»çº¿è¿è¡Œï¼Œä¿æŠ¤éšç§
```

## ğŸ§© å®Œæ•´æŠ€æœ¯æ ˆæ–¹æ¡ˆ

### æ ¸å¿ƒç»„ä»¶
| ç»„ä»¶ | é€‰æ‹© | ä½œç”¨ |
|------|------|------|
| **Webæ¡†æ¶** | FastAPI | æ„å»ºé«˜æ€§èƒ½APIç«¯ç‚¹ |
| **AIæ¡†æ¶** | LangChain | è¿æ¥çŸ¥è¯†åº“å’Œè¯­è¨€æ¨¡å‹ |
| **çŸ¥è¯†åº“** | Trilium Notes | æœ¬åœ°çŸ¥è¯†å­˜å‚¨ |
| **å‘é‡æ•°æ®åº“** | Chroma(æœ¬åœ°) | å­˜å‚¨çŸ¥è¯†åº“åµŒå…¥å‘é‡ |
| **åµŒå…¥æ¨¡å‹** | sentence-transformers | æ–‡æœ¬å‘é‡åŒ– |
| **è¯­è¨€æ¨¡å‹** | GPT4All/Llama.cpp | æœ¬åœ°è¿è¡Œçš„å¤§æ¨¡å‹ |
| **å‰ç«¯** | Streamlit/Gradio | å¿«é€Ÿæ„å»ºäº¤äº’ç•Œé¢ |

## ğŸš€ ç³»ç»Ÿæ¶æ„è®¾è®¡

```mermaid
graph TD
A[ç”¨æˆ·æé—®] --> B(FastAPI WebæœåŠ¡)
B --> C{LangChainæ™ºèƒ½ä½“}
C --> D[Trilium NotesçŸ¥è¯†åº“]
C --> E[å‘é‡æ•°æ®åº“]
C --> F[æœ¬åœ°è¯­è¨€æ¨¡å‹]
F --> G[ç”Ÿæˆå›ç­”]
G --> H[è¿”å›ç»™ç”¨æˆ·]
```

## ğŸ”§ å…·ä½“å®ç°æ­¥éª¤

### 1. é…ç½® Trilium æ•°æ®è®¿é—®
```python
from langchain.document_loaders import TriliumLoader

# è¿æ¥åˆ°æœ¬åœ° Trilium å®ä¾‹
loader = TriliumLoader(
base_url="http://localhost:8080",
token="YOUR_API_TOKEN",# Triliumçš„APIä»¤ç‰Œ
note_ids=["root"]# ä»æ ¹ç¬”è®°å¼€å§‹
)

# åŠ è½½çŸ¥è¯†åº“æ–‡æ¡£
documents = loader.load()
```

### 2. åˆ›å»ºå‘é‡çŸ¥è¯†åº“
```python
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter

# åˆ†å‰²æ–‡æ¡£
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
texts = text_splitter.split_documents(documents)

# åˆ›å»ºåµŒå…¥æ¨¡å‹
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# åˆ›å»ºæœ¬åœ°å‘é‡æ•°æ®åº“
vector_db = Chroma.from_documents(
documents=texts,
embedding=embeddings,
persist_directory="./chroma_db"
)
```

### 3. æ„å»ºæ™ºèƒ½é—®ç­”é“¾
```python
from langchain.chains import RetrievalQA
from langchain.llms import GPT4All

# åŠ è½½æœ¬åœ°è¯­è¨€æ¨¡å‹
llm = GPT4All(
model="./models/ggml-gpt4all-j-v1.3-groovy.bin",
n_ctx=2048,
backend='gptj',
verbose=False
)

# åˆ›å»ºæ£€ç´¢å¼é—®ç­”é“¾
qa_chain = RetrievalQA.from_chain_type(
llm=llm,
chain_type="stuff",
retriever=vector_db.as_retriever(search_kwargs={"k": 3}),
return_source_documents=True
)
```

### 4. åˆ›å»º FastAPI æœåŠ¡
```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

class QuestionRequest(BaseModel):
question: str

@app.post("/ask")
async def ask_question(request: QuestionRequest):
# ä½¿ç”¨çŸ¥è¯†åº“å¢å¼ºçš„é—®ç­”é“¾
result = qa_chain({"query": request.question})

return {
"answer": result["result"],
"sources": [doc.metadata["source"] for doc in result["source_documents"]]
}
```

### 5. æ·»åŠ å‰ç«¯ç•Œé¢ (å¯é€‰)
```python
# ä½¿ç”¨ Streamlit å¿«é€Ÿåˆ›å»ºç•Œé¢
import streamlit as st
from backend import qa_chain# å¯¼å…¥ä¸Šé¢åˆ›å»ºçš„é—®ç­”é“¾

st.title("TriliumçŸ¥è¯†åº“æ™ºèƒ½åŠ©æ‰‹")
question = st.text_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜:")

if question:
result = qa_chain({"query": question})
st.write("### å›ç­”:")
st.write(result["result"])

st.write("### æ¥æºç¬”è®°:")
for doc in result["source_documents"]:
st.write(f"- {doc.metadata['source']}")
```

## ğŸ§  é«˜çº§åŠŸèƒ½å¢å¼º

### çŸ¥è¯†åº“è‡ªåŠ¨æ›´æ–°ç›‘æ§
```python
import time
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

class TriliumChangeHandler(FileSystemEventHandler):
def on_modified(self, event):
if "notes" in event.src_path:
print("æ£€æµ‹åˆ°çŸ¥è¯†åº“æ›´æ–°ï¼Œé‡æ–°åŠ è½½...")
# é‡æ–°åŠ è½½çŸ¥è¯†åº“å’Œæ›´æ–°å‘é‡æ•°æ®åº“

# å¯åŠ¨ç›‘æ§
observer = Observer()
observer.schedule(TriliumChangeHandler(), path="/path/to/trilium/data", recursive=True)
observer.start()
```

### å¯¹è¯å†å²è®°å¿†
```python
from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory(
memory_key="chat_history",
return_messages=True
)

# åˆ›å»ºå¸¦è®°å¿†çš„å¯¹è¯é“¾
conversational_qa = ConversationalRetrievalChain.from_llm(
llm=llm,
retriever=vector_db.as_retriever(),
memory=memory
)
```

## âš™ï¸ éƒ¨ç½²æ–¹æ¡ˆ

### æœ¬åœ°éƒ¨ç½²
```bash
# å®‰è£…ä¾èµ–
pip install fastapi uvicorn langchain chromadb sentence-transformers gpt4all

# å¯åŠ¨æœåŠ¡
uvicorn main:app --reload --port 8000
```

### Docker éƒ¨ç½²
```dockerfile
FROM python:3.10-slim

WORKDIR /app
COPY . .

RUN pip install -r requirements.txt

# ä¸‹è½½æ¨¡å‹
RUN wget https://gpt4all.io/models/ggml-gpt4all-j-v1.3-groovy.bin -P ./models

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **å¢é‡æ›´æ–°**ï¼šåªå¤„ç†Triliumä¸­å˜æ›´çš„ç¬”è®°ï¼Œé¿å…å…¨é‡é‡å»ºç´¢å¼•
2. **æ¨¡å‹é‡åŒ–**ï¼šä½¿ç”¨4-bité‡åŒ–çš„æœ¬åœ°æ¨¡å‹å‡å°å†…å­˜å ç”¨
3. **ç¼“å­˜æœºåˆ¶**ï¼šå¯¹å¸¸è§é—®é¢˜ç­”æ¡ˆè¿›è¡Œç¼“å­˜
4. **åˆ†çº§æ£€ç´¢**ï¼šå…ˆå…³é”®è¯æ£€ç´¢ç¼©å°èŒƒå›´ï¼Œå†è¯­ä¹‰æ£€ç´¢

**æ€»ç»“**ï¼šä½¿ç”¨ **FastAPI + LangChain + æœ¬åœ°LLM(GPT4All/Llama)** çš„ç»„åˆï¼Œä½ å¯ä»¥æ„å»ºä¸€ä¸ªå®Œå…¨æœ¬åœ°çš„æ™ºèƒ½ä½“ç³»ç»Ÿï¼Œå……åˆ†åˆ©ç”¨Trilium Notesä¸­çš„çŸ¥è¯†æä¾›ç²¾å‡†å›ç­”ï¼ŒåŒæ—¶ä¿æŠ¤æ•°æ®éšç§ã€‚è¿™ä¸ªæ–¹æ¡ˆå…¼é¡¾äº†æ€§èƒ½ã€å‡†ç¡®æ€§å’Œå®‰å…¨æ€§ï¼Œç‰¹åˆ«é€‚åˆéœ€è¦å¤„ç†æ•æ„Ÿæ•°æ®çš„åœºæ™¯ã€‚